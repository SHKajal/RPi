{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+ZuBQJS0mxNWsRgvSAJ8n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHKajal/RPi/blob/main/CNN_2_Binary_col_586.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjUyQjpjCsd5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZhCWjvmzgD-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve7mFVs-zgD-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/CCIC-CIC-AndMal-2020/all_cat_586_col_Label.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj9wmuzdzgEF"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXAvCJGezgEG"
      },
      "outputs": [],
      "source": [
        "y = df.Category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyrGj9bKzgEG"
      },
      "outputs": [],
      "source": [
        "X = df.drop('Category', axis=1,inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTZ_kFUozgEH"
      },
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwKvL-5SzgEH"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.MinMaxScaler().fit(X)\n",
        "X = scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeE-MAj5zgEH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=.50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHXLBNZHzgEH"
      },
      "outputs": [],
      "source": [
        "del X\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNyaIOnOzgEI"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Convolution1D, MaxPooling1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1JHwH1VzgEI"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution1D(64, kernel_size=12, padding=\"same\",activation=\"relu\",input_shape=(X_train.shape[1], 1))) # df.shape = (105692, 9504)\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution1D(128, kernel_size=6, padding=\"same\",activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=(3)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution1D(128, kernel_size=3, padding=\"same\",activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "# model.add(Dense(6, activation='relu'))\n",
        "# model.add(Dense(2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bM3EcNS1zgEI"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/Models/CNN_2_Binary_col_587/weights/50.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eM-mNWDNzgEJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Nadam(0.0001),\n",
        "    metrics=['binary_accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxq9gK3pzgEJ"
      },
      "outputs": [],
      "source": [
        "saving_path = '/content/drive/MyDrive/Models/CNN_2_Binary_col_587'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezYtT4KWzgEJ"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = saving_path + \"/weights/{epoch:02d}.h5\"\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=False,\n",
        "    save_best_only=False,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_freq='epoch',\n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4NwGf1rzgEo"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYdI25WOzgEp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred.round(), digits=4)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf89kMXbzgEp"
      },
      "outputs": [],
      "source": [
        "with open(saving_path + \"/history.txt\", 'w') as file:\n",
        "    file.write(str(history.history))\n",
        "\n",
        "with open(saving_path + \"/report.txt\", 'w') as file:\n",
        "    file.write(str(report))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tFw8m3vzgEq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the training and validation metrics from the history object\n",
        "train_acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10))\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax1.plot(train_acc, label='Train Accuracy')\n",
        "ax1.plot(val_acc, label='Validation Accuracy')\n",
        "ax1.set_title('Accuracy')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "\n",
        "# Plot training and validation loss\n",
        "ax2.plot(train_loss, label='Train Loss')\n",
        "ax2.plot(val_loss, label='Validation Loss')\n",
        "ax2.set_title('Loss')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.legend()\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# Display the figure\n",
        "plt.show()\n"
      ]
    }
  ]
}